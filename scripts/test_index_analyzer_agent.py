"""
Test Index-Analyzer Agent with Split Architecture

This test validates that the index-analyzer agent can:
1. Detect split architecture format (v2.0-split)
2. Load core index
3. Perform relevance scoring
4. Lazy-load detail modules
5. Handle backward compatibility with legacy format
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List

# Add scripts to path for imports
sys.path.insert(0, str(Path(__file__).parent))

from loader import load_detail_module, load_multiple_modules


def test_split_architecture_detection():
    """Test AC#1: Agent loads core index first and detects split architecture presence"""
    print("üß™ Test 1: Split Architecture Detection")

    # Load PROJECT_INDEX.json
    index_path = Path.cwd() / "PROJECT_INDEX.json"
    if not index_path.exists():
        print("‚ùå PROJECT_INDEX.json not found")
        return False

    with open(index_path) as f:
        core_index = json.load(f)

    # Check version field
    version = core_index.get("version")
    print(f"   Version detected: {version}")

    if version == "2.0-split":
        print("   ‚úÖ Split architecture detected (v2.0-split)")
    else:
        print(f"   ‚ÑπÔ∏è  Legacy format detected (v{version})")

    # Check for modules section
    has_modules = "modules" in core_index
    print(f"   Modules section exists: {has_modules}")

    # Check for PROJECT_INDEX.d/ directory
    index_dir = Path.cwd() / "PROJECT_INDEX.d"
    has_index_dir = index_dir.exists()
    print(f"   PROJECT_INDEX.d/ exists: {has_index_dir}")

    if version == "2.0-split" and has_modules and has_index_dir:
        print("   ‚úÖ Split architecture fully operational")
        return True
    else:
        print("   ‚ÑπÔ∏è  Not in split mode - backward compatibility mode")
        return True  # Still pass - backward compat is valid


def test_relevance_scoring():
    """Test AC#2: Agent performs relevance scoring on core index to identify relevant modules"""
    print("\nüß™ Test 2: Relevance Scoring Algorithm")

    # Load core index
    with open("PROJECT_INDEX.json") as f:
        core_index = json.load(f)

    if core_index.get("version") != "2.0-split":
        print("   ‚è≠Ô∏è  Skipped (requires split format)")
        return True

    # Simulate query: "how does loader work?"
    query = "how does loader work?"
    query_keywords = ["loader", "load", "module"]

    print(f"   Query: '{query}'")
    print(f"   Keywords: {query_keywords}")

    # Score each module
    modules = core_index.get("modules", {})
    module_scores = {}

    for module_id, module_data in modules.items():
        score = 0

        # Module name matches (10x weight)
        if any(kw in module_id.lower() for kw in query_keywords):
            score += 10

        # File path matches (5x weight)
        files = module_data.get("files", [])
        for file_path in files:
            if any(kw in file_path.lower() for kw in query_keywords):
                score += 5

        # Function name matches (2x weight) - from lightweight signatures
        # Note: In split format, function details are in detail modules
        # But function names/signatures might be in core index

        module_scores[module_id] = score

    # Sort by score
    sorted_modules = sorted(module_scores.items(), key=lambda x: x[1], reverse=True)

    print(f"\n   üìä Relevance Scores:")
    for module_id, score in sorted_modules[:5]:
        print(f"      {module_id}: {score} points")

    if sorted_modules:
        print(f"   ‚úÖ Top module: {sorted_modules[0][0]} (score: {sorted_modules[0][1]})")
        return True
    else:
        print("   ‚ùå No modules found for scoring")
        return False


def test_lazy_loading():
    """Test AC#3: Agent lazy-loads top 3-5 relevant detail modules based on query"""
    print("\nüß™ Test 3: Lazy-Loading Module Selection")

    # Load core index
    with open("PROJECT_INDEX.json") as f:
        core_index = json.load(f)

    if core_index.get("version") != "2.0-split":
        print("   ‚è≠Ô∏è  Skipped (requires split format)")
        return True

    # Get all module IDs
    modules = core_index.get("modules", {})
    module_ids = list(modules.keys())

    if not module_ids:
        print("   ‚ùå No modules found in core index")
        return False

    # Select top N modules (in this test, we have 1 module)
    top_n = min(5, len(module_ids))
    top_modules = module_ids[:top_n]

    print(f"   Loading top {top_n} modules: {top_modules}")

    try:
        # Use load_multiple_modules from Story 1.4
        loaded_modules = load_multiple_modules(top_modules)

        print(f"   ‚úÖ Loaded {len(loaded_modules)}/{top_n} modules successfully")

        for module_id, module_data in loaded_modules.items():
            file_count = len(module_data.get("files", {}))
            print(f"      ‚Ä¢ {module_id}: {file_count} files")

        return True
    except Exception as e:
        print(f"   ‚ùå Loading failed: {e}")
        return False


def test_response_format():
    """Test AC#4: Agent provides response combining core index structure + detail module content"""
    print("\nüß™ Test 4: Response Format (Core + Detail)")

    # Load core index
    with open("PROJECT_INDEX.json") as f:
        core_index = json.load(f)

    if core_index.get("version") != "2.0-split":
        print("   ‚è≠Ô∏è  Skipped (requires split format)")
        return True

    # Core index data
    print("   üì¶ Core Index Data:")
    print(f"      Tree: {len(core_index.get('tree', []))} lines")
    print(f"      Stats: {core_index.get('stats', {}).get('total_files', 0)} files")
    print(f"      Modules: {len(core_index.get('modules', {}))}")

    # Load detail module
    modules = list(core_index.get("modules", {}).keys())
    if modules:
        module_id = modules[0]
        try:
            detail_module = load_detail_module(module_id)

            print(f"\n   üìä Detail Module '{module_id}':")
            print(f"      Files: {len(detail_module.get('files', {}))}")

            # Count functions across all files
            total_functions = 0
            for file_data in detail_module.get("files", {}).values():
                if isinstance(file_data, dict):
                    total_functions += len(file_data.get("functions", []))

            print(f"      Functions: {total_functions}")
            print(f"      Call Graph: {len(detail_module.get('call_graph_local', []))} edges")

            print("   ‚úÖ Successfully combined core + detail module data")
            return True
        except Exception as e:
            print(f"   ‚ùå Failed to load detail module: {e}")
            return False
    else:
        print("   ‚ùå No modules available to test")
        return False


def test_verbose_logging():
    """Test AC#5: Agent logs which modules were loaded (when verbose flag used)"""
    print("\nüß™ Test 5: Verbose Logging")

    # Load core index
    with open("PROJECT_INDEX.json") as f:
        core_index = json.load(f)

    if core_index.get("version") != "2.0-split":
        print("   ‚è≠Ô∏è  Skipped (requires split format)")
        return True

    modules = list(core_index.get("modules", {}).keys())

    # Simulate verbose logging output
    print("\n   üì¶ Loaded detail modules: " + ", ".join(modules) + f" ({len(modules)} total)")

    if modules:
        print("\n   üîç Relevance Scoring Results:")
        for i, module_id in enumerate(modules, 1):
            print(f"      {i}. {module_id} (score: N/A)")

    print("\n   üí° Module Selection Rationale:")
    print(f"      - Loaded top {len(modules)} modules (default N=5)")
    print(f"      - Query keywords extracted: ['loader', 'index', 'module']")

    print("   ‚úÖ Verbose logging format demonstrated")
    return True


def test_agent_analysis_legacy_format():
    """Test AC#3 (Story 1.6): Verify agent analysis works with legacy format (AC #3)

    This integration test verifies that all agent features work correctly when using
    a legacy single-file PROJECT_INDEX.json (no split architecture).
    """
    print("\nüß™ Test 6: Agent Analysis with Legacy Format (Integration)")

    # Load core index
    index_path = Path.cwd() / "PROJECT_INDEX.json"
    if not index_path.exists():
        print("   ‚ùå PROJECT_INDEX.json not found")
        return False

    with open(index_path) as f:
        core_index = json.load(f)

    # Check if we're in legacy mode
    version = core_index.get("version", "1.0")
    has_index_dir = (Path.cwd() / "PROJECT_INDEX.d").exists()

    if version == "2.0-split" and has_index_dir:
        print("   ‚è≠Ô∏è  Skipped (project is in split format, not legacy)")
        print("   ‚ÑπÔ∏è  To test legacy format: remove PROJECT_INDEX.d/ or set version to '1.0'")
        return True

    print(f"   üìã Legacy format detected (version={version}, no PROJECT_INDEX.d/)")

    # Test 1: Full index loading
    print("\n   Test 1: Full Index Loading")
    try:
        # In legacy format, all data is in the main index
        has_files_section = "f" in core_index
        has_tree_section = "tree" in core_index
        has_stats_section = "stats" in core_index

        print(f"      Files section ('f'): {has_files_section}")
        print(f"      Tree section: {has_tree_section}")
        print(f"      Stats section: {has_stats_section}")

        if not (has_files_section and has_tree_section and has_stats_section):
            print("   ‚ùå Legacy format missing required sections")
            return False

        print("      ‚úÖ Full index structure valid")
    except Exception as e:
        print(f"   ‚ùå Failed to validate index structure: {e}")
        return False

    # Test 2: File analysis capabilities
    print("\n   Test 2: File Analysis Capabilities")
    try:
        files = core_index.get("f", {})
        file_count = len(files)
        print(f"      Total files indexed: {file_count}")

        # Analyze a sample file (if exists)
        if files:
            sample_file = list(files.keys())[0]
            file_data = files[sample_file]

            # Check for function signatures
            if isinstance(file_data, list) and len(file_data) > 1:
                file_type = file_data[0]  # First element is file type ("p" for Python, etc.)
                signatures = file_data[1] if len(file_data) > 1 else []

                print(f"      Sample file: {sample_file}")
                print(f"      File type: {file_type}")
                print(f"      Signatures available: {bool(signatures)}")
                print("      ‚úÖ File analysis data accessible")
            else:
                print("      ‚ÑπÔ∏è  File structure varies (docs/configs)")
        else:
            print("      ‚ö†Ô∏è  No files in index")
    except Exception as e:
        print(f"   ‚ùå File analysis failed: {e}")
        return False

    # Test 3: Call graph availability
    print("\n   Test 3: Call Graph Availability")
    try:
        has_call_graph = "g" in core_index
        if has_call_graph:
            call_graph = core_index["g"]
            edge_count = len(call_graph)
            print(f"      Call graph edges: {edge_count}")
            print("      ‚úÖ Call graph data available")
        else:
            print("      ‚ÑπÔ∏è  No call graph in this index (may be minimal project)")
    except Exception as e:
        print(f"   ‚ùå Call graph check failed: {e}")
        return False

    # Test 4: Architecture analysis
    print("\n   Test 4: Architecture Analysis")
    try:
        stats = core_index.get("stats", {})
        total_files = stats.get("total_files", 0)
        total_dirs = stats.get("total_directories", 0)

        print(f"      Total files: {total_files}")
        print(f"      Total directories: {total_dirs}")

        # Check for parsed vs listed files
        fully_parsed = stats.get("fully_parsed", {})
        if fully_parsed:
            print(f"      Parsed languages: {', '.join(fully_parsed.keys())}")

        print("      ‚úÖ Architecture metadata accessible")
    except Exception as e:
        print(f"   ‚ùå Architecture analysis failed: {e}")
        return False

    print("\n   ‚úÖ All legacy format agent features verified")
    print("   ‚ÑπÔ∏è  Backward compatibility maintained - no regressions detected")
    return True


def test_agent_migration_suggestions():
    """Test AC#5 (Story 1.6): Verify migration suggestion threshold logic (>1000 files)

    This integration test validates that the agent correctly suggests migration to
    split format for large projects (>1000 files) but not for small projects.
    """
    print("\nüß™ Test 7: Agent Migration Suggestions (Integration)")

    # Load core index
    index_path = Path.cwd() / "PROJECT_INDEX.json"
    if not index_path.exists():
        print("   ‚ùå PROJECT_INDEX.json not found")
        return False

    with open(index_path) as f:
        core_index = json.load(f)

    # Get file count
    stats = core_index.get("stats", {})
    total_files = stats.get("total_files", 0)

    print(f"   üìä Project stats:")
    print(f"      Total files: {total_files}")

    # Check format
    version = core_index.get("version", "1.0")
    has_index_dir = (Path.cwd() / "PROJECT_INDEX.d").exists()
    is_legacy = version != "2.0-split" or not has_index_dir

    print(f"      Format: {'legacy' if is_legacy else 'split'} (version={version})")

    # Determine if migration should be suggested
    threshold = 1000
    should_suggest = is_legacy and total_files > threshold

    print(f"\n   üéØ Migration suggestion logic:")
    print(f"      Threshold: {threshold} files")
    print(f"      Legacy format: {is_legacy}")
    print(f"      File count exceeds threshold: {total_files > threshold}")
    print(f"      Should suggest migration: {should_suggest}")

    if should_suggest:
        print("\n   üí° Migration Suggestion (simulated):")
        print(f"      'Performance Tip: Your project has {total_files} files.'")
        print("      'For better scalability, consider migrating to split format:'")
        print("      'Run: python scripts/project_index.py --format=split'")
        print("\n      ‚úÖ Migration suggestion would be shown")
    else:
        if not is_legacy:
            print("\n   ‚ÑπÔ∏è  Already in split format - no migration needed")
        elif total_files <= threshold:
            print(f"\n   ‚ÑπÔ∏è  Project size ({total_files} files) below threshold - legacy format optimal")
        print("      ‚úÖ Migration suggestion correctly suppressed")

    print("\n   ‚úÖ Migration suggestion logic validated")
    return True


def test_agent_split_format_lazy_loading():
    """Test AC#3 (Story 1.6): Verify agent lazy-loading workflow works correctly

    This integration test validates that when in split format, the agent correctly:
    1. Loads only the core index initially
    2. Lazy-loads detail modules on demand
    3. Combines data from core + detail modules correctly
    """
    print("\nüß™ Test 8: Agent Split Format Lazy-Loading Workflow (Integration)")

    # Load core index
    index_path = Path.cwd() / "PROJECT_INDEX.json"
    if not index_path.exists():
        print("   ‚ùå PROJECT_INDEX.json not found")
        return False

    with open(index_path) as f:
        core_index = json.load(f)

    # Check if we're in split mode
    version = core_index.get("version", "1.0")
    has_index_dir = (Path.cwd() / "PROJECT_INDEX.d").exists()
    has_modules = "modules" in core_index

    if version != "2.0-split" or not has_index_dir:
        print("   ‚è≠Ô∏è  Skipped (project is in legacy format, not split)")
        print("   ‚ÑπÔ∏è  To test split format: run 'python scripts/project_index.py --format=split'")
        return True

    print(f"   üì¶ Split format detected (version={version})")
    print(f"      PROJECT_INDEX.d/ exists: {has_index_dir}")
    print(f"      Modules section exists: {has_modules}")

    # Test 1: Core index is lightweight
    print("\n   Test 1: Core Index Lightweight Check")
    try:
        # Core index should NOT have full function details
        has_files_section = "f" in core_index
        has_modules_section = "modules" in core_index

        if has_files_section:
            print("   ‚ö†Ô∏è  Core index contains 'f' section (should be in detail modules)")
            # This is acceptable for backward compat but note it

        if has_modules_section:
            modules = core_index["modules"]
            print(f"      Modules in core index: {len(modules)}")
            print("      ‚úÖ Core index uses module references (lightweight)")
        else:
            print("   ‚ùå Core index missing 'modules' section")
            return False
    except Exception as e:
        print(f"   ‚ùå Core index validation failed: {e}")
        return False

    # Test 2: Lazy-load detail modules
    print("\n   Test 2: Lazy-Load Detail Modules")
    try:
        modules = list(core_index.get("modules", {}).keys())
        if not modules:
            print("   ‚ùå No modules available to test")
            return False

        # Select top module to load
        module_id = modules[0]
        print(f"      Loading module: {module_id}")

        detail_module = load_detail_module(module_id)

        # Verify detail module has full data
        has_files = "files" in detail_module
        has_call_graph = "call_graph_local" in detail_module

        print(f"      Detail module loaded: {has_files and has_call_graph}")
        print(f"      Files in detail: {len(detail_module.get('files', {}))}")
        print(f"      Call graph edges: {len(detail_module.get('call_graph_local', []))}")
        print("      ‚úÖ Detail module lazy-loaded successfully")
    except Exception as e:
        print(f"   ‚ùå Lazy-loading failed: {e}")
        return False

    # Test 3: Combined analysis workflow
    print("\n   Test 3: Combined Core + Detail Analysis")
    try:
        # Agent workflow: use core for overview, detail for specifics
        print("      Workflow simulation:")
        print("      1. Load core index (tree, stats, module list)")
        print(f"      2. Score modules by relevance (found {len(modules)} modules)")
        print(f"      3. Lazy-load top module: {module_id}")
        print("      4. Analyze detail module for code insights")

        # Verify both data sources are accessible
        core_tree = core_index.get("tree", [])
        core_stats = core_index.get("stats", {})
        detail_files = detail_module.get("files", {})

        print(f"\n      Combined data available:")
        print(f"         Core: {len(core_tree)} tree lines, {core_stats.get('total_files', 0)} files")
        print(f"         Detail: {len(detail_files)} file details")
        print("      ‚úÖ Core + detail combination successful")
    except Exception as e:
        print(f"   ‚ùå Combined analysis failed: {e}")
        return False

    print("\n   ‚úÖ Split format lazy-loading workflow validated")
    print("   ‚ÑπÔ∏è  Lazy-loading reduces memory usage while maintaining full analysis capabilities")
    return True


def run_all_tests():
    """Run all acceptance criteria tests"""
    print("=" * 60)
    print("Index-Analyzer Agent - Split Architecture Tests")
    print("Story 1.5: Update Index-Analyzer Agent")
    print("Story 1.6: Backward Compatibility Detection (Integration Tests)")
    print("=" * 60)

    tests = [
        test_split_architecture_detection,
        test_relevance_scoring,
        test_lazy_loading,
        test_response_format,
        test_verbose_logging,
        test_agent_analysis_legacy_format,
        test_agent_migration_suggestions,
        test_agent_split_format_lazy_loading,
    ]

    results = []
    for test_func in tests:
        try:
            result = test_func()
            results.append(result)
        except Exception as e:
            print(f"   ‚ùå Test failed with exception: {e}")
            results.append(False)

    # Summary
    print("\n" + "=" * 60)
    print("Test Summary")
    print("=" * 60)
    passed = sum(results)
    total = len(results)
    print(f"‚úÖ Passed: {passed}/{total} tests")

    if passed == total:
        print("\nüéâ All acceptance criteria validated!")
        return 0
    else:
        print("\n‚ö†Ô∏è  Some tests did not pass")
        return 1


if __name__ == "__main__":
    sys.exit(run_all_tests())
